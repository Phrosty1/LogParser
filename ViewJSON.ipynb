{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Beachhead/Misc/LogTinker/outdata/ALL/2021-09-25.parquet\n",
      "C:/Beachhead/Misc/LogTinker/outdata/ALL/2021-09-20.parquet\n",
      "C:/Beachhead/Misc/LogTinker/outdata/ALL/2021-09-20.parquet\n",
      "C:/Beachhead/Misc/LogTinker/outdata/ALL/2021-10-01.parquet\n"
     ]
    }
   ],
   "source": [
    "import re, pandas as pd, numpy as np, os\n",
    "from io import StringIO\n",
    "from IPython.core.display import display\n",
    "import time # time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(1634309423832/1000))\n",
    "# print(pd.api.types.infer_dtype([78.064002990723,78.064002990723]))\n",
    "destfolder = 'C:/Beachhead/Misc/LogTinker/outdata/'\n",
    "csvdtype = {'seq': int, 'timestamp': 'int64', 'player': 'category', 'event': 'category'}\n",
    "csvNumArgs = [\"arg\"+str(i) for i in range(1, 25)]\n",
    "for arg in csvNumArgs: csvdtype[arg] = 'str'\n",
    "csvcols = \";\".join(csvdtype.keys())\n",
    "jsondat = pd.read_json(StringIO('''{\"events\":[\n",
    "   {\"name\":\"EVENT_COMBAT_EVENT\", \"arguments\":[\n",
    "      {\"name\":\"result\", \"type\":\"category\"},\n",
    "      {\"name\":\"isError\", \"type\":\"category\"},\n",
    "      {\"name\":\"abilityName\", \"type\":\"category\"},\n",
    "      {\"name\":\"abilityGraphic\", \"type\":\"category\"},\n",
    "      {\"name\":\"abilityActionSlotType\", \"type\":\"category\"},\n",
    "      {\"name\":\"sourceName\", \"type\":\"category\"},\n",
    "      {\"name\":\"sourceType\", \"type\":\"category\"},\n",
    "      {\"name\":\"targetName\", \"type\":\"category\"},\n",
    "      {\"name\":\"targetType\", \"type\":\"category\"},\n",
    "      {\"name\":\"hitValue\", \"type\":\"int\"},\n",
    "      {\"name\":\"powerType\", \"type\":\"category\"},\n",
    "      {\"name\":\"damageType\", \"type\":\"category\"},\n",
    "      {\"name\":\"log\", \"type\":\"category\"},\n",
    "      {\"name\":\"sourceUnitId\", \"type\":\"category\"},\n",
    "      {\"name\":\"targetUnitId\", \"type\":\"category\"},\n",
    "      {\"name\":\"abilityId\", \"type\":\"category\"},\n",
    "      {\"name\":\"overflow\", \"type\":\"category\"}\n",
    "   ]},\n",
    "   {\"name\":\"EVENT_EFFECT_CHANGED\", \"arguments\":[\n",
    "      {\"name\":\"changeType\", \"type\":\"category\"},\n",
    "      {\"name\":\"effectSlot\", \"type\":\"int\"},\n",
    "      {\"name\":\"effectName\", \"type\":\"category\"},\n",
    "      {\"name\":\"unitTag\", \"type\":\"category\"},\n",
    "      {\"name\":\"beginTime\", \"type\":\"float\"},\n",
    "      {\"name\":\"endTime\", \"type\":\"float\"},\n",
    "      {\"name\":\"stackCount\", \"type\":\"category\"},\n",
    "      {\"name\":\"iconName\", \"type\":\"category\"},\n",
    "      {\"name\":\"buffType\", \"type\":\"category\"},\n",
    "      {\"name\":\"effectType\", \"type\":\"category\"},\n",
    "      {\"name\":\"abilityType\", \"type\":\"category\"},\n",
    "      {\"name\":\"statusEffectType\", \"type\":\"category\"},\n",
    "      {\"name\":\"unitName\", \"type\":\"category\"},\n",
    "      {\"name\":\"unitId\", \"type\":\"int\"},\n",
    "      {\"name\":\"abilityId\", \"type\":\"int\"},\n",
    "      {\"name\":\"sourceType\", \"type\":\"category\"}\n",
    "   ]}\n",
    "]}'''))\n",
    "if not os.path.exists(destfolder+'ALL'): os.makedirs(destfolder+'ALL')\n",
    "events = []\n",
    "for jsonEvent in jsondat[\"events\"]:\n",
    "   eventName = jsonEvent['name']\n",
    "   destEventPath = destfolder+eventName\n",
    "   if not os.path.exists(destEventPath): os.makedirs(destEventPath)\n",
    "   eventArguments = jsonEvent['arguments']\n",
    "   eventDfCols = ['seq', 'timestamp', 'player']\n",
    "   eventDfCols.extend(csvNumArgs[:len(eventArguments)])\n",
    "   eventArgRename = dict(zip(csvNumArgs[:len(eventArguments)], [x['name'] for x in eventArguments]))\n",
    "   eventArgTypes = {x['name']:x['type'] for x in eventArguments}\n",
    "   events.append({'eventName':eventName, 'destEventPath':destEventPath, 'eventDfCols':eventDfCols, 'eventArgRename':eventArgRename, 'eventArgTypes':eventArgTypes})\n",
    "\n",
    "def loadRaw(sourcefilename):\n",
    "    with open(sourcefilename, \"r\", encoding='utf8') as sourcefile:\n",
    "        pseudocsv = sourcefile.read()\n",
    "        pseudocsv = pseudocsv[pseudocsv.find(\"[1]\"):pseudocsv.rfind(\"\\\",\")+2]\n",
    "        pseudocsv = pseudocsv.replace(\"\\\\\\\"\",\":quot:\")\n",
    "        pseudocsv = re.sub(\"\\[(\\d+)\\]\\s?=\\s?\\\"(.*?)\\\",\\s*\", \"\\\\1;\\\\2\\\\n\", pseudocsv)\n",
    "        pseudocsv = pseudocsv.replace(\":quot:\",\"\\\\\\\"\")\n",
    "        return pd.read_csv(StringIO(csvcols+\"\\n\"+pseudocsv), dtype=csvdtype, sep=\";\", header=0)\n",
    "def mergeDataFrameIntoFile(eventDataFrame, fileNameEventDate): # pd.read_parquet(fileNameEventDate).append(eventDataFrame).drop_duplicates(subset=[\"seq\", \"timestamp\", \"player\"]).to_parquet(fileNameEventDate)\n",
    "   try:\n",
    "      fileDataFrame = pd.read_parquet(fileNameEventDate)\n",
    "   except FileNotFoundError:\n",
    "      eventDataFrame.to_parquet(fileNameEventDate) # create new file since none exists\n",
    "   else:\n",
    "      cnt = len(fileDataFrame)\n",
    "      fileDataFrame = fileDataFrame.append(eventDataFrame)\n",
    "      fileDataFrame.drop_duplicates(subset=[\"seq\", \"timestamp\", \"player\"], inplace=True)\n",
    "      if len(fileDataFrame) != cnt :\n",
    "         fileDataFrame.to_parquet(fileNameEventDate) # appending records made a difference so update the file\n",
    "\n",
    "rawfiles = [\"B916DF15A205777A0E6C358803A6E204.lson\", \"2136039DCAB1882ACD05B5FAE568858D.lson\", \"E0B499D2E7E6CBA2868D3830BE4EDE4C.lson\", \"E376DE68C859549B2CD3F9629B3DD5DB.lson\"]\n",
    "for rawfile in rawfiles:\n",
    "   df = loadRaw(rawfile)\n",
    "   fileprefix = time.strftime('%Y-%m-%d', time.localtime(df['timestamp'].values[-1]/1000))\n",
    "   fileNameEventDate = destfolder+'ALL/'+fileprefix+'.parquet'\n",
    "   print(fileNameEventDate)\n",
    "   # df.to_parquet(destfolder+'ALL/'+fileprefix+'.parquet')\n",
    "   mergeDataFrameIntoFile(df, fileNameEventDate)\n",
    "   for e in events:\n",
    "      eventDataFrame = pd.DataFrame(df[df[\"event\"] == e['eventName']], columns=e['eventDfCols']).rename(columns=e['eventArgRename']).astype(dtype=e['eventArgTypes'])\n",
    "      fileNameEventDate = e['destEventPath']+'/'+fileprefix+'.parquet'\n",
    "      mergeDataFrameIntoFile(eventDataFrame, fileNameEventDate)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aca1fb4539d4c99fd60799fd39b2b25b1bcb4cad2c67307b87ec2b2cc61eb539"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('exploration': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
